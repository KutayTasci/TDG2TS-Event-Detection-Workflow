{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Example Code for Dynamic AE and RNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\tr\\anaconda3\\envs\\cmp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\tr\\anaconda3\\envs\\cmp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\tr\\anaconda3\\envs\\cmp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\tr\\anaconda3\\envs\\cmp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\tr\\anaconda3\\envs\\cmp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\tr\\anaconda3\\envs\\cmp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dynamicgem.utils.dnn_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5a2f6f1361b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdynamicgem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_dynamic_sbm_embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdynamicgem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_generation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdynamic_SBM_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdynamicgem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdnn_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdynamicgem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mevaluate_link_prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dynamicgem.utils.dnn_utils'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "disp_avlbl = True\n",
    "if os.name == 'posix' and 'DISPLAY' not in os.environ:\n",
    "    disp_avlbl = False\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import operator\n",
    "from argparse import ArgumentParser\n",
    "from time import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from dynamicgem.embedding.dynAERNN import DynAERNN\n",
    "from dynamicgem.utils import plot_util, graph_util, dataprep_util\n",
    "from dynamicgem.visualization import plot_dynamic_sbm_embedding\n",
    "from dynamicgem.graph_generation import dynamic_SBM_graph\n",
    "from dynamicgem.utils.dnn_utils import *\n",
    "from dynamicgem.evaluation import evaluate_link_prediction\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser(description='Learns node embeddings for a sequence of graph snapshots')\n",
    "    parser.add_argument('-t', '--testDataType',\n",
    "                        default='sbm_cd',\n",
    "                        type=str,\n",
    "                        help='Type of data to test the code')\n",
    "    parser.add_argument('-c', '--criteria',\n",
    "                        default='degree',\n",
    "                        type=str,\n",
    "                        help='Node Migration criteria')\n",
    "    parser.add_argument('-rc', '--criteria_r',\n",
    "                        default=True,\n",
    "                        type=bool,\n",
    "                        help='Take highest centrality measure to perform node migration')\n",
    "    parser.add_argument('-l', '--timelength',\n",
    "                        default=4,\n",
    "                        type=int,\n",
    "                        help='Number of time series graph to generate')\n",
    "    parser.add_argument('-lb', '--lookback',\n",
    "                        default=2,\n",
    "                        type=int,\n",
    "                        help='number of lookbacks')\n",
    "    parser.add_argument('-nm', '--nodemigration',\n",
    "                        default=2,\n",
    "                        type=int,\n",
    "                        help='number of nodes to migrate')\n",
    "    parser.add_argument('-iter', '--epochs',\n",
    "                        default=2,\n",
    "                        type=int,\n",
    "                        help='number of epochs')\n",
    "    parser.add_argument('-emb', '--embeddimension',\n",
    "                        default=16,\n",
    "                        type=int,\n",
    "                        help='embedding dimension')\n",
    "    parser.add_argument('-rd', '--resultdir',\n",
    "                        type=str,\n",
    "                        default='./results_link_all',\n",
    "                        help=\"result directory name\")\n",
    "    parser.add_argument('-sm', '--samples',\n",
    "                        default=5,\n",
    "                        type=int,\n",
    "                        help='samples for test data')\n",
    "    parser.add_argument('-eta', '--learningrate',\n",
    "                        default=1e-3,\n",
    "                        type=float,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('-bs', '--batch',\n",
    "                        default=10,\n",
    "                        type=int,\n",
    "                        help='batch size')\n",
    "    parser.add_argument('-ht', '--hypertest',\n",
    "                        default=0,\n",
    "                        type=int,\n",
    "                        help='hyper test')\n",
    "    parser.add_argument('-fs', '--show',\n",
    "                        default=0,\n",
    "                        type=int,\n",
    "                        help='show figure ')\n",
    "    parser.add_argument('-exp', '--exp',\n",
    "                        default='lp',\n",
    "                        type=str,\n",
    "                        help='experiments (lp, emb)')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    epochs = args.epochs\n",
    "    dim_emb = args.embeddimension\n",
    "    lookback = args.lookback\n",
    "    length = args.timelength\n",
    "\n",
    "    if not os.path.exists('./intermediate'):\n",
    "          os.mkdir('./intermediate')\n",
    "\n",
    "    if length < 7:\n",
    "        length = 7\n",
    "    lookback = args.lookback\n",
    "\n",
    "    if args.testDataType == 'sbm_rp':\n",
    "        node_num = 1000\n",
    "        community_num = 50\n",
    "        node_change_num = 10\n",
    "        dynamic_sbm_series = dynamic_SBM_graph.get_random_perturbation_series(node_num, community_num, length,\n",
    "                                                                              node_change_num)\n",
    "        dynamic_embedding = DynAERNN(\n",
    "            d=100,\n",
    "            beta=100,\n",
    "            n_prev_graphs=lookback,\n",
    "            nu1=1e-6,\n",
    "            nu2=1e-6,\n",
    "            n_units=[50, 30, ],\n",
    "            rho=0.3,\n",
    "            n_iter=30,\n",
    "            xeta=0.005,\n",
    "            n_batch=50,\n",
    "            modelfile=['./intermediate/enc_model.json', './intermediate/dec_model.json'],\n",
    "            weightfile=['./intermediate/enc_weights.hdf5', './intermediate/dec_weights.hdf5'],\n",
    "        )\n",
    "        dynamic_embedding.learn_embeddings([g[0] for g in dynamic_sbm_series])\n",
    "        plot_dynamic_sbm_embedding.plot_dynamic_sbm_embedding(dynamic_embedding.get_embeddings(), dynamic_sbm_series)\n",
    "        plt.savefig('result/visualization_DynRNN_rp.png')\n",
    "        plt.show()\n",
    "    elif args.testDataType == 'sbm_cd':\n",
    "        node_num = 100\n",
    "        community_num = 2\n",
    "        node_change_num = args.nodemigration\n",
    "        dynamic_sbm_series = dynamic_SBM_graph.get_community_diminish_series_v2(node_num,\n",
    "                                                                                community_num, length, 1,\n",
    "                                                                                node_change_num)\n",
    "        dynamic_embedding = DynAERNN(\n",
    "            d=dim_emb,\n",
    "            beta=5,\n",
    "            n_prev_graphs=lookback,\n",
    "            nu1=1e-6,\n",
    "            nu2=1e-6,\n",
    "            n_aeunits=[500, 300],\n",
    "            n_lstmunits=[500, dim_emb],\n",
    "            rho=0.3,\n",
    "            n_iter=epochs,\n",
    "            xeta=args.learningrate,\n",
    "            n_batch=args.batch,\n",
    "            modelfile=['./intermediate/enc_model.json', './intermediate/dec_model.json'],\n",
    "            weightfile=['./intermediate/enc_weights.hdf5', './intermediate/dec_weights.hdf5'],\n",
    "            savefilesuffix=\"testing\"\n",
    "        )\n",
    "        graphs = [g[0] for g in dynamic_sbm_series]\n",
    "\n",
    "        outdir = args.resultdir\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "        outdir = outdir + '/' + args.testDataType\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "\n",
    "        outdir = outdir + '/dynAERNN'\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "\n",
    "        if args.exp == 'emb':\n",
    "            embs = []\n",
    "            result = Parallel(n_jobs=4)(delayed(dynamic_embedding.learn_embeddings)(graphs[:temp_var]) for temp_var in\n",
    "                                        range(lookback + 1, length + 1))\n",
    "            for i in range(len(result)):\n",
    "                embs.append(np.asarray(result[i][0]))\n",
    "            plt.figure()\n",
    "            plt.clf()\n",
    "            plot_dynamic_sbm_embedding.plot_dynamic_sbm_embedding_v2(embs[-5:-1], dynamic_sbm_series[-5:])\n",
    "            plt.savefig(\n",
    "                './' + outdir + '/V_DynAERNN_nm' + str(args.nodemigration) + '_l' + str(length) + '_epoch' + str(\n",
    "                    epochs) + '_emb' + str(dim_emb) + '.pdf', bbox_inches='tight', dpi=600)\n",
    "            plt.show()\n",
    "\n",
    "        if args.hypertest == 1:\n",
    "            fname = 'epoch' + str(args.epochs) + '_bs' + str(args.batch) + '_lb' + str(args.lookback) + '_eta' + str(\n",
    "                args.learningrate) + '_emb' + str(args.embeddimension)\n",
    "        else:\n",
    "            fname = 'nm' + str(args.nodemigration) + '_l' + str(length) + '_emb' + str(dim_emb)\n",
    "\n",
    "        if args.exp == 'lp':\n",
    "            evaluate_link_prediction.expLP(\n",
    "                graphs,\n",
    "                dynamic_embedding,\n",
    "                1,\n",
    "                outdir + '/',\n",
    "                fname,\n",
    "            )\n",
    "\n",
    "    elif args.testDataType == 'academic':\n",
    "        print(\"datatype:\", args.testDataType)\n",
    "\n",
    "        dynamic_embedding = DynAERNN(\n",
    "            d=dim_emb,\n",
    "            beta=5,\n",
    "            n_prev_graphs=lookback,\n",
    "            nu1=1e-6,\n",
    "            nu2=1e-6,\n",
    "            n_aeunits=[500, 300],\n",
    "            n_lstmunits=[500, dim_emb],\n",
    "            rho=0.3,\n",
    "            n_iter=epochs,\n",
    "            xeta=1e-3,\n",
    "            n_batch=100,\n",
    "            modelfile=['./intermediate/enc_modelAERNN.json', './intermediate/dec_modelAERNN.json'],\n",
    "            weightfile=['./intermediate/enc_weightsAERNN.hdf5', './intermediate/dec_weightsAERNN.hdf5'],\n",
    "            savefilesuffix=\"testing\"\n",
    "        )\n",
    "\n",
    "        sample = args.samples\n",
    "        if not os.path.exists('./test_data/academic/pickle'):\n",
    "            os.mkdir('./test_data/academic/pickle')\n",
    "            graphs, length = dataprep_util.get_graph_academic('./test_data/academic/adjlist')\n",
    "            for i in range(length):\n",
    "                nx.write_gpickle(graphs[i], './test_data/academic/pickle/' + str(i))\n",
    "        else:\n",
    "            length = len(os.listdir('./test_data/academic/pickle'))\n",
    "            graphs = []\n",
    "            for i in range(length):\n",
    "                graphs.append(nx.read_gpickle('./test_data/academic/pickle/' + str(i)))\n",
    "\n",
    "        G_cen = nx.degree_centrality(graphs[29])  # graph 29 in academia has highest number of edges\n",
    "        G_cen = sorted(G_cen.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        node_l = []\n",
    "        i = 0\n",
    "        while i < sample:\n",
    "            node_l.append(G_cen[i][0])\n",
    "            i += 1\n",
    "        # pdb.set_trace()\n",
    "        # node_l = np.random.choice(range(graphs[29].number_of_nodes()), 5000, replace=False)\n",
    "        # print(node_l)\n",
    "        for i in range(length):\n",
    "            graphs[i] = graph_util.sample_graph_nodes(graphs[i], node_l)\n",
    "        # pdb.set_trace()\n",
    "\n",
    "        outdir = args.resultdir\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "        outdir = outdir + '/' + args.testDataType\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "\n",
    "        outdir = outdir + '/dynAERNN'\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "\n",
    "        if args.exp == 'emb':\n",
    "            print('plotting embedding not implemented!')\n",
    "\n",
    "        if args.exp == 'lp':\n",
    "            evaluate_link_prediction.expLP(graphs[-args.timelength:],\n",
    "                                           dynamic_embedding,\n",
    "                                           1,\n",
    "                                           outdir + '/',\n",
    "                                           'lb' + str(lookback) + '_l' + str(args.timelength) + '_emb' + str(\n",
    "                                               dim_emb) + '_samples' + str(sample),\n",
    "                                           n_sample_nodes=graphs[i].number_of_nodes()\n",
    "                                           )\n",
    "\n",
    "    elif args.testDataType == 'hep':\n",
    "        print(\"datatype:\", args.testDataType)\n",
    "        dynamic_embedding = DynAERNN(\n",
    "            d=dim_emb,\n",
    "            beta=5,\n",
    "            n_prev_graphs=lookback,\n",
    "            nu1=1e-6,\n",
    "            nu2=1e-6,\n",
    "            n_aeunits=[500, 300],\n",
    "            n_lstmunits=[500, dim_emb],\n",
    "            rho=0.3,\n",
    "            n_iter=epochs,\n",
    "            xeta=1e-3,\n",
    "            n_batch=100,\n",
    "            modelfile=['./intermediate/enc_modelAERNN.json', './intermediate/dec_modelAERNN.json'],\n",
    "            weightfile=['./intermediate/enc_weightsAERNN.hdf5', './intermediate/dec_weightsAERNN.hdf5'],\n",
    "            savefilesuffix=\"testing\"\n",
    "        )\n",
    "\n",
    "        if not os.path.exists('./test_data/hep/pickle'):\n",
    "            os.mkdir('./test_data/hep/pickle')\n",
    "            files = [file for file in os.listdir('./test_data/hep/hep-th') if '.gpickle' in file]\n",
    "            length = len(files)\n",
    "            graphs = []\n",
    "            for i in range(length):\n",
    "                G = nx.read_gpickle('./test_data/hep/hep-th/month_' + str(i + 1) + '_graph.gpickle')\n",
    "\n",
    "                graphs.append(G)\n",
    "            total_nodes = graphs[-1].number_of_nodes()\n",
    "\n",
    "            for i in range(length):\n",
    "                for j in range(total_nodes):\n",
    "                    if j not in graphs[i].nodes():\n",
    "                        graphs[i].add_node(j)\n",
    "\n",
    "            for i in range(length):\n",
    "                nx.write_gpickle(graphs[i], './test_data/hep/pickle/' + str(i))\n",
    "        else:\n",
    "            length = len(os.listdir('./test_data/hep/pickle'))\n",
    "            graphs = []\n",
    "            for i in range(length):\n",
    "                graphs.append(nx.read_gpickle('./test_data/hep/pickle/' + str(i)))\n",
    "\n",
    "        # pdb.set_trace()            \n",
    "        sample = args.samples\n",
    "        G_cen = nx.degree_centrality(graphs[-1])  # graph 29 in academia has highest number of edges\n",
    "        G_cen = sorted(G_cen.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        node_l = []\n",
    "        i = 0\n",
    "        while i < sample:\n",
    "            node_l.append(G_cen[i][0])\n",
    "            i += 1\n",
    "        for i in range(length):\n",
    "            graphs[i] = graph_util.sample_graph_nodes(graphs[i], node_l)\n",
    "\n",
    "        outdir = args.resultdir\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "        outdir = outdir + '/' + args.testDataType\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "\n",
    "        outdir = outdir + '/dynAERNN'\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "\n",
    "        if args.exp == 'emb':\n",
    "            print('plotting embedding not implemented!')\n",
    "\n",
    "        if args.exp == 'lp':\n",
    "            evaluate_link_prediction.expLP(graphs[-args.timelength:],\n",
    "                                           dynamic_embedding,\n",
    "                                           1,\n",
    "                                           outdir + '/',\n",
    "                                           'lb' + str(lookback) + '_l' + str(args.timelength) + '_emb' + str(\n",
    "                                               dim_emb) + '_samples' + str(sample),\n",
    "                                           n_sample_nodes=graphs[i].number_of_nodes()\n",
    "                                           )\n",
    "\n",
    "    elif args.testDataType == 'AS':\n",
    "        print(\"datatype:\", args.testDataType)\n",
    "        dynamic_embedding = DynAERNN(\n",
    "            d=dim_emb,\n",
    "            beta=5,\n",
    "            n_prev_graphs=lookback,\n",
    "            nu1=1e-6,\n",
    "            nu2=1e-6,\n",
    "            n_aeunits=[500, 300],\n",
    "            n_lstmunits=[500, dim_emb],\n",
    "            rho=0.3,\n",
    "            n_iter=epochs,\n",
    "            xeta=1e-3,\n",
    "            n_batch=100,\n",
    "            modelfile=['./intermediate/enc_modelAERNN.json', './intermediate/dec_modelAERNN.json'],\n",
    "            weightfile=['./intermediate/enc_weightsAERNN.hdf5', './intermediate/dec_weightsAERNN.hdf5'],\n",
    "            savefilesuffix=\"testing\"\n",
    "        )\n",
    "\n",
    "        files = [file for file in os.listdir('./test_data/AS/as-733') if '.gpickle' in file]\n",
    "        length = len(files)\n",
    "        graphs = []\n",
    "\n",
    "        for i in range(length):\n",
    "            G = nx.read_gpickle('./test_data/AS/as-733/month_' + str(i + 1) + '_graph.gpickle')\n",
    "            graphs.append(G)\n",
    "\n",
    "        sample = args.samples\n",
    "        G_cen = nx.degree_centrality(graphs[-1])  # graph 29 in academia has highest number of edges\n",
    "        G_cen = sorted(G_cen.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        node_l = []\n",
    "        i = 0\n",
    "        while i < sample:\n",
    "            node_l.append(G_cen[i][0])\n",
    "            i += 1\n",
    "        for i in range(length):\n",
    "            graphs[i] = graph_util.sample_graph_nodes(graphs[i], node_l)\n",
    "\n",
    "        outdir = args.resultdir\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "        outdir = outdir + '/' + args.testDataType\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "\n",
    "        outdir = outdir + '/dynAERNN'\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "\n",
    "        if args.exp == 'emb':\n",
    "            print('plotting embedding not implemented!')\n",
    "\n",
    "        if args.exp == 'lp':\n",
    "            evaluate_link_prediction.expLP(graphs[-args.timelength:],\n",
    "                                           dynamic_embedding,\n",
    "                                           1,\n",
    "                                           outdir + '/',\n",
    "                                           'lb' + str(lookback) + '_l' + str(args.timelength) + '_emb' + str(\n",
    "                                               dim_emb) + '_samples' + str(sample),\n",
    "                                           n_sample_nodes=graphs[i].number_of_nodes()\n",
    "                                           )\n",
    "\n",
    "    elif args.testDataType == 'enron':\n",
    "        print(\"datatype:\", args.testDataType)\n",
    "        dynamic_embedding = DynAERNN(\n",
    "            d=dim_emb,\n",
    "            beta=5,\n",
    "            n_prev_graphs=lookback,\n",
    "            nu1=1e-4,\n",
    "            nu2=1e-4,\n",
    "            n_aeunits=[100, 80],\n",
    "            n_lstmunits=[100, 20],\n",
    "            rho=0.3,\n",
    "            n_iter=2000,\n",
    "            xeta=1e-7,\n",
    "            n_batch=100,\n",
    "            modelfile=['./intermediate/enc_modelAERNN.json', './intermediate/dec_modelAERNN.json'],\n",
    "            weightfile=['./intermediate/enc_weightsAERNN.hdf5', './intermediate/dec_weightsAERNN.hdf5'],\n",
    "            savefilesuffix=\"testing\"\n",
    "        )\n",
    "\n",
    "        files = [file for file in os.listdir('./test_data/enron') if 'week' in file]\n",
    "        length = len(files)\n",
    "        graphsall = []\n",
    "\n",
    "        for i in range(length):\n",
    "            G = nx.read_gpickle('./test_data/enron/week_' + str(i) + '_graph.gpickle')\n",
    "            graphsall.append(G)\n",
    "\n",
    "        sample = graphsall[0].number_of_nodes()\n",
    "\n",
    "        outdir = args.resultdir\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "        outdir = outdir + '/' + args.testDataType\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "\n",
    "        outdir = outdir + '/dynAERNN'\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "        graphs = graphsall[-args.timelength:]\n",
    "\n",
    "        if args.exp == 'emb':\n",
    "            print('plotting embedding not implemented!')\n",
    "\n",
    "        if args.exp == 'lp':\n",
    "            evaluate_link_prediction.expLP(graphs,\n",
    "                                           dynamic_embedding,\n",
    "                                           1,\n",
    "                                           outdir + '/',\n",
    "                                           'lb' + str(lookback) + '_l' + str(args.timelength) + '_emb' + str(\n",
    "                                               dim_emb) + '_samples' + str(sample),\n",
    "                                           n_sample_nodes=sample\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
